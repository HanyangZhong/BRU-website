# Introduction
This project investigates how large language models (LLMs) handle **cognitive biases** during multiple-choice question answering (MCQA), challenging the prevailing assumption that all biases are harmful. Instead, we explore how certain *rational deviations*‚Äîbiases that mimic human heuristics‚Äîcan sometimes enhance decision-making efficiency.

We introduce **heuristic moderation** and a novel **abstention mechanism**, enabling LLMs to refrain from answering when uncertain. This approach significantly reduces error rates and improves answer validity. Our experiments, conducted on the newly developed **BRU (Balance Rigor and Utility)** dataset, show that selective bias inspection‚Äîespecially *Specific Bias Inspection (SBI)*‚Äîcombined with abstention leads to substantial performance gains in models like GPT-4 and Gemini 1.0 Pro.

üîç **Key Features**:
- A principled framework for understanding and managing rational deviations in LLMs.
- Strategic use of abstention to reduce incorrect answers in uncertain scenarios.
- The BRU dataset: 200+ expertly designed MCQs targeting 8 types of cognitive bias (e.g., base rate fallacy, sunk cost, conjunction fallacy).
- New evaluation metrics: **Decisiveness Rate**, **Error Rate**, and **Valid Vote Accuracy**.
- A **Bias Detection Module** (powered by GPT-4o) that dynamically adjusts inspection scope via feedback loops.

üìä **Highlights**:
- üß† GPT-4 + SBI + Abstention achieves **93.5% Valid Vote Accuracy**, with only **3.9% Error Rate**.
- üí° SBI consistently outperforms General Bias Inspection (GBI), showing the value of targeted prompting.
- üö´ LLMs exhibit fewer fallacies when given the option to *say "I don't know"*.

# Our Workflow

![](./carousel/figure02_new.png)
QA examples from GPT-4. The Conjunction Fallacy is a subset of cognitive biases. Scaling the scope of bias inspection can influence rational deviations, thereby impacting the outcomes of LLMs' reasoning. To address this, we propose a feedback loop Bias Detection module to identify the type of bias and adjust the inspection scope when an abstention from answering is considered. This approach ensures that LLMs provide more accurate responses by systematically addressing biases during decision-making.
# Dataset information

![](./carousel/frames.png)
This diagram pertains to the specific details of dataset design and the classification of questions, with the numbers in parentheses indicating the quantity of questions in each category.
# Numerical results

![Figure Title](./carousel/new_first2.png)
Valid vote accuracy and error rates on the BRU dataset for LLMs balancing rational deviations, both with and without the option to abstain.

![Figure Title](./carousel/new_figure4.png)
Prediction accuracy and error rate of GPT-4, Gemini 1.0 Pro, and LLaMA3-70B in Non-Abstention and Abstention experiments (%) on the BRU dataset with different prompting strategies. Bold numbers indicate the relative extrema. Differences between Standard groups with and without abstention are shown with +- values in black.

![Figure Title](./carousel/new_figure5.png)
The combination of TT, TF, FT, FF, and O rates for GPT-4, Gemini 1.0 Pro, and LLaMA3-70B on the BRU dataset using different prompting strategies. 'NA-' denotes Non-Abstention, 'A-' denotes Abstention, and 'Sta' represents the Standard used for comparison.

# Numerical results details
## GBI and SBI
![Figure Title](./carousel/table3.png)
Model GPT-4, Gemini 1.0 Pro and LLaMA3-70B prediction accuracy for Non-Abstention experiments (%) on BRU dataset
![Figure Title](./carousel/table4.png)
Model GPT-4, Gemini 1.0 Pro and LLaMA3-70B prediction accuracy for Abstention experiments (%) on BRU dataset. ‚ÄôN/A‚Äô indicates that there was no response in this category.
![Figure Title](./carousel/table5.png)
The percentage (%) of TT, TF, FT, FF, and O in abstention experiment for GPT-4, Gemini 1.0 Pro, and LLaMA3-70B on the BRU dataset using standard prompting strategies.
![Figure Title](./carousel/table6.png)
The percentage (%) of TT, TF, FT, FF, and O in abstention experiment for GPT-4, Gemini 1.0 Pro, and LLaMA3-70B on the BRU dataset using GBI prompting strategies.
![Figure Title](./carousel/table7.png)
The percentage (%) of TT, TF, FT, FF, and O in abstention experiment for GPT-4, Gemini 1.0 Pro, and LLaMA3-70B on the BRU dataset using SBI prompting strategies.

## Transformation results details
![Figure Title](./carousel/table8.png)
This table presents the accuracy (%) of GPT-4o in detecting specific bias traps within the Bias Detection Loop.
‚ÄùDirect matching‚Äù refers to instances where GPT-4o accurately identifies the exact subtype associated with a particular bias. In
contrast, ‚Äùindirect matching‚Äù denotes cases where GPT-4o recognizes either the broader parent category or a synonym of the
bias subtype.

# Testing examples
## Examples of answers with different biases
![Figure Title](./carousel/table9.png)
Examples of dataset questions. Here are Base Rate Fallacy and Gambler‚Äôs Fallacy, which include question types and corresponding quantities. The table categorizes questions into two types: ‚ÄùQuestions Containing Numerical Information,‚Äù where explicit numerical data is provided, and ‚ÄùQuestions Without Numerical Information,‚Äù where no specific numbers are included.
![Figure Title](./carousel/table10-1.png)
![Figure Title](./carousel/table10-2.png)
Examples of dataset questions. Here are Base Rate Fallacy and Gambler‚Äôs Fallacy, which include question types
and corresponding quantities. The table categorizes questions into two types: ‚ÄùActive Selection Questions,‚Äù which require
participants to make an explicit choice between options based on a scenario, and ‚ÄùObjective Analysis Questions,‚Äù which prompt
participants to analyze a situation and identify the underlying cognitive bias or psychological effect.

![Figure Title](./carousel/table11-1.png)

![Figure Title](./carousel/table11-2.png)
Examples of dataset questions. Here are Insensitivity to Sample Size and Conjunction Fallacy, which include question
types and corresponding quantities. The table categorizes Insensitivity to Sample Size questions into two types: ‚ÄùSample Size
Discrepancy of 10-fold,‚Äù where the comparison is made between two groups with a tenfold difference in sample size, and
‚ÄùSample Size Discrepancy of 10 to 100-fold,‚Äù where the sample size difference is broader, ranging from 10 to 100 times.

![Figure Title](./carousel/table12-1.png)

![Figure Title](./carousel/table12-1.png)
Examples of dataset questions. Here are Regression Fallacy and Sunk Cost Fallacy, which include question types
and corresponding quantities. The table categorizes Regression Fallacy questions into two types: ‚ÄùSingle-Event Assessment
Questions,‚Äù where participants assess a scenario based on a single event or change, and ‚ÄùMultiple-Event Assessment Questions,‚Äù
where the scenario involves a series of events or observations over time.

![Figure Title](./carousel/table13.png)
Examples of GPT-4 Standard prompt reasoning in abstention experiment about Base Rate Fallacy
![Figure Title](./carousel/table14.png)
Examples of GPT-4 GBI prompt reasoning in abstention experiment about Base Rate Fallacy.

![Figure Title](./carousel/table15.png)
Examples of GPT-4 SBI prompt reasoning in abstention experiment about Base Rate Fallacy


## Examples of response in Transformation setup
![Figure Title](./carousel/table16.png)
Examples of GPT-4o‚Äôs reasoning in the Bias Detection Module regarding the Base Rate Fallacy. This instance
demonstrates a direct match for the bias type within the given question.

![Figure Title](./carousel/table17.png)
Examples of GPT-4o‚Äôs reasoning in the Bias Detection Module regarding the Conjunction Fallacy. This instance
demonstrates an indirect match for the parent category of bias type within the given question.

## Examples of response of the whole Workflow
![Figure Title](./carousel/table18.png)
![Figure Title](./carousel/table19.png)
This table provides a detailed demonstration of the process depicted in Fig. 2. Light green represents the GBI prompt, orange indicates the SBI prompt, light blue denotes the bias detection prompt, and
purple signifies the answer. The example illustrates how, upon the Bias Detection module identifying the corresponding
category of the question type, the SBI prompt is triggered, successfully leading to the correct result.

![Figure Title](./carousel/table20.png)
![Figure Title](./carousel/table21.png)
This table provides a detailed demonstration of the process depicted in Fig. 2. Light green represents the GBI prompt, orange indicates the SBI prompt, light blue denotes the bias detection prompt, and purple signifies the answer.
The example illustrates how, upon the Bias Detection module identifying the parent category of the question type, the SBI prompt is triggered, successfully leading to the correct result.
